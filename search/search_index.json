{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Edgy Graph","text":"<p>The Typed Graph Library for Python</p> \ud83d\udcd6 API Reference \ud83d\udd17 GitHub"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install edgygraph\n</code></pre> <p>Requires Python 3.13</p>"},{"location":"api/diff/","title":"Diff","text":""},{"location":"api/diff/#src.edgygraph.diff.ChangeTypes","title":"<code>ChangeTypes</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enum for the types of changes that can be made to a State.</p> Source code in <code>src/edgygraph/diff.py</code> <pre><code>class ChangeTypes(StrEnum):\n    \"\"\"\n    Enum for the types of changes that can be made to a State.\n    \"\"\"\n\n    ADDED = auto()\n    REMOVED = auto()\n    UPDATED = auto()\n</code></pre>"},{"location":"api/diff/#src.edgygraph.diff.Change","title":"<code>Change</code>","text":"<p>               Bases: <code>RichReprMixin</code>, <code>BaseModel</code></p> <p>Represents a change made to a State.</p> Source code in <code>src/edgygraph/diff.py</code> <pre><code>class Change(RichReprMixin, BaseModel):\n    \"\"\"\n    Represents a change made to a State.\n    \"\"\"\n\n    type: ChangeTypes\n    old: Any\n    new: Any\n</code></pre>"},{"location":"api/diff/#src.edgygraph.diff.Diff","title":"<code>Diff</code>","text":"<p>Utility class for computing differences between states.</p> Source code in <code>src/edgygraph/diff.py</code> <pre><code>class Diff:\n    \"\"\"\n    Utility class for computing differences between states.\n    \"\"\"\n\n\n    @classmethod\n    def find_conflicts(cls, changes: list[dict[tuple[Hashable, ...], Change]]) -&gt; dict[tuple[Hashable, ...], list[Change]]:\n        \"\"\"\n        Finds conflicts in a list of changes.\n\n        Args:\n           changes: A list of dictionaries representing changes to a state.\n\n        Returns:\n            A dictionary mapping a path in the state as a list of keys to lists of conflicting changes directly under that path.\n        \"\"\"\n\n        if len(changes) &lt;= 1:\n            return {}\n\n        counts = Counter(key for d in changes for key in d)\n\n        duplicate_keys = [k for k, count in counts.items() if count &gt; 1]\n\n        conflicts: dict[tuple[Hashable, ...], list[Change]] = {}        \n        for key in duplicate_keys:\n            conflicts[key] = [d[key] for d in changes if key in d]\n\n        return conflicts\n\n\n    @classmethod\n    def recursive_diff(cls, old: Any, new: Any, path: tuple[Hashable, ...] | None = None) -&gt; dict[tuple[Hashable, ...], Change]:\n        \"\"\"\n        Recursively computes the differences between two dictionaries.\n\n\n        Args:\n            old: Part of the old dictionary.\n            new: Part of the new dictionary.\n            path: The current path of the parts in the full dictionary as a list of keys from least to most specific.\n\n        Returns:\n            A mapping of the path to the changes directly on that level.\n        \"\"\"\n\n        path = path or ()\n        changes: dict[tuple[Hashable, ...], Change] = {}\n\n        if isinstance(old, dict) and isinstance(new, dict):\n            all_keys: set[str] = set(old.keys()) | set(new.keys()) #type: ignore\n\n            for key in all_keys:\n                current_path: tuple[Hashable, ...] = (*path, key)\n\n                if key in old and not key in new:\n                    changes[current_path] = Change(type=ChangeTypes.REMOVED, old=old[key], new=None)\n                elif key in new and not key in old:\n                    changes[current_path] = Change(type=ChangeTypes.ADDED, old=None, new=new[key])\n                else:\n                    sub_changes = cls.recursive_diff(old[key], new[key], current_path)\n                    changes.update(sub_changes)\n\n        elif old != new:\n            changes[path] = Change(type=ChangeTypes.UPDATED, old=old, new=new)\n\n        return changes\n\n\n    @classmethod\n    def apply_changes(cls, target: dict[Hashable, Any], changes: dict[tuple[Hashable, ...], Change]) -&gt; None:\n        \"\"\"\n        Applies a set of changes to the target dictionary.\n\n\n        Args:\n            target: The dictionary to apply the changes to.\n            changes: A mapping of paths to changes. The paths are tuples of keys that lead to the value that needs to changes. The changes are applied in the dictionary on that level.\n        \"\"\"\n\n        for path, change in changes.items():\n            cursor = target\n\n            # Navigate down the dictionary\n            for part in path[:-1]:\n                if part not in cursor:\n                    cursor[part] = {} # If the path was created because of ADDED\n                cursor = cursor[part]\n\n            last_key = path[-1]\n\n            if change.type == ChangeTypes.REMOVED:\n                print(\"DELETE KEY:\")\n                print(last_key)\n                if last_key in cursor:\n                    del cursor[last_key]\n                else:\n                    raise KeyError(f\"Unable to remove key: {last_key} not found in target dictionary under path {path} from {target}\")\n\n            else:\n                # UPDATED or ADDED\n                cursor[last_key] = change.new\n</code></pre>"},{"location":"api/diff/#src.edgygraph.diff.Diff.find_conflicts","title":"<code>find_conflicts(changes)</code>  <code>classmethod</code>","text":"<p>Finds conflicts in a list of changes.</p> <p>Parameters:</p> Name Type Description Default <code>changes</code> <code>list[dict[tuple[Hashable, ...], Change]]</code> <p>A list of dictionaries representing changes to a state.</p> required <p>Returns:</p> Type Description <code>dict[tuple[Hashable, ...], list[Change]]</code> <p>A dictionary mapping a path in the state as a list of keys to lists of conflicting changes directly under that path.</p> Source code in <code>src/edgygraph/diff.py</code> <pre><code>@classmethod\ndef find_conflicts(cls, changes: list[dict[tuple[Hashable, ...], Change]]) -&gt; dict[tuple[Hashable, ...], list[Change]]:\n    \"\"\"\n    Finds conflicts in a list of changes.\n\n    Args:\n       changes: A list of dictionaries representing changes to a state.\n\n    Returns:\n        A dictionary mapping a path in the state as a list of keys to lists of conflicting changes directly under that path.\n    \"\"\"\n\n    if len(changes) &lt;= 1:\n        return {}\n\n    counts = Counter(key for d in changes for key in d)\n\n    duplicate_keys = [k for k, count in counts.items() if count &gt; 1]\n\n    conflicts: dict[tuple[Hashable, ...], list[Change]] = {}        \n    for key in duplicate_keys:\n        conflicts[key] = [d[key] for d in changes if key in d]\n\n    return conflicts\n</code></pre>"},{"location":"api/diff/#src.edgygraph.diff.Diff.recursive_diff","title":"<code>recursive_diff(old, new, path=None)</code>  <code>classmethod</code>","text":"<p>Recursively computes the differences between two dictionaries.</p> <p>Parameters:</p> Name Type Description Default <code>old</code> <code>Any</code> <p>Part of the old dictionary.</p> required <code>new</code> <code>Any</code> <p>Part of the new dictionary.</p> required <code>path</code> <code>tuple[Hashable, ...] | None</code> <p>The current path of the parts in the full dictionary as a list of keys from least to most specific.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[tuple[Hashable, ...], Change]</code> <p>A mapping of the path to the changes directly on that level.</p> Source code in <code>src/edgygraph/diff.py</code> <pre><code>@classmethod\ndef recursive_diff(cls, old: Any, new: Any, path: tuple[Hashable, ...] | None = None) -&gt; dict[tuple[Hashable, ...], Change]:\n    \"\"\"\n    Recursively computes the differences between two dictionaries.\n\n\n    Args:\n        old: Part of the old dictionary.\n        new: Part of the new dictionary.\n        path: The current path of the parts in the full dictionary as a list of keys from least to most specific.\n\n    Returns:\n        A mapping of the path to the changes directly on that level.\n    \"\"\"\n\n    path = path or ()\n    changes: dict[tuple[Hashable, ...], Change] = {}\n\n    if isinstance(old, dict) and isinstance(new, dict):\n        all_keys: set[str] = set(old.keys()) | set(new.keys()) #type: ignore\n\n        for key in all_keys:\n            current_path: tuple[Hashable, ...] = (*path, key)\n\n            if key in old and not key in new:\n                changes[current_path] = Change(type=ChangeTypes.REMOVED, old=old[key], new=None)\n            elif key in new and not key in old:\n                changes[current_path] = Change(type=ChangeTypes.ADDED, old=None, new=new[key])\n            else:\n                sub_changes = cls.recursive_diff(old[key], new[key], current_path)\n                changes.update(sub_changes)\n\n    elif old != new:\n        changes[path] = Change(type=ChangeTypes.UPDATED, old=old, new=new)\n\n    return changes\n</code></pre>"},{"location":"api/diff/#src.edgygraph.diff.Diff.apply_changes","title":"<code>apply_changes(target, changes)</code>  <code>classmethod</code>","text":"<p>Applies a set of changes to the target dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>dict[Hashable, Any]</code> <p>The dictionary to apply the changes to.</p> required <code>changes</code> <code>dict[tuple[Hashable, ...], Change]</code> <p>A mapping of paths to changes. The paths are tuples of keys that lead to the value that needs to changes. The changes are applied in the dictionary on that level.</p> required Source code in <code>src/edgygraph/diff.py</code> <pre><code>@classmethod\ndef apply_changes(cls, target: dict[Hashable, Any], changes: dict[tuple[Hashable, ...], Change]) -&gt; None:\n    \"\"\"\n    Applies a set of changes to the target dictionary.\n\n\n    Args:\n        target: The dictionary to apply the changes to.\n        changes: A mapping of paths to changes. The paths are tuples of keys that lead to the value that needs to changes. The changes are applied in the dictionary on that level.\n    \"\"\"\n\n    for path, change in changes.items():\n        cursor = target\n\n        # Navigate down the dictionary\n        for part in path[:-1]:\n            if part not in cursor:\n                cursor[part] = {} # If the path was created because of ADDED\n            cursor = cursor[part]\n\n        last_key = path[-1]\n\n        if change.type == ChangeTypes.REMOVED:\n            print(\"DELETE KEY:\")\n            print(last_key)\n            if last_key in cursor:\n                del cursor[last_key]\n            else:\n                raise KeyError(f\"Unable to remove key: {last_key} not found in target dictionary under path {path} from {target}\")\n\n        else:\n            # UPDATED or ADDED\n            cursor[last_key] = change.new\n</code></pre>"},{"location":"api/diff/#src.edgygraph.diff.ChangeConflictException","title":"<code>ChangeConflictException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised when a conflict between changes to a state is detected.</p> Source code in <code>src/edgygraph/diff.py</code> <pre><code>class ChangeConflictException(Exception):\n    \"\"\"\n    Exception raised when a conflict between changes to a state is detected.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/nodes/","title":"Nodes","text":""},{"location":"api/nodes/#src.edgygraph.nodes.Node","title":"<code>Node</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Represents a node in the graph.</p> <p>The generic types define the type of state and shared state that the node expects. Due to variance the node can also take any subtype of the state and shared state.</p> <p>The node must implement the <code>__call__</code> method to run the node.</p> Source code in <code>src/edgygraph/nodes.py</code> <pre><code>class Node[T: StateProtocol = StateProtocol, S: SharedProtocol = SharedProtocol](ABC):\n    \"\"\"\n    Represents a node in the graph.\n\n    The generic types define the type of state and shared state that the node expects.\n    Due to variance the node can also take any subtype of the state and shared state.\n\n    The node must implement the `__call__` method to run the node.\n    \"\"\"\n\n    @abstractmethod\n    async def __call__(self, state: T, shared: S) -&gt; None:\n        \"\"\"\n        Runs the node with the given state and shared state from the graph.\n\n        Operations on the state are merged in the graphs state after the node has finished.\n        Therefore, the state is not shared between nodes and operations are safe.\n\n        Operations on the shared state are reflected in all parallel running nodes.\n        Therefore, the shared state is shared between nodes and operations are not safe without using the Lock.\n        The lock can be accessed via `shared.lock`.\n\n        Args:\n            state: The state of the graph.\n            shared: The shared state of the graph.\n\n        Returns:\n            None. The instance references of the arguments are used in the graph to enable variance.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/nodes/#src.edgygraph.nodes.Node.__call__","title":"<code>__call__(state, shared)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Runs the node with the given state and shared state from the graph.</p> <p>Operations on the state are merged in the graphs state after the node has finished. Therefore, the state is not shared between nodes and operations are safe.</p> <p>Operations on the shared state are reflected in all parallel running nodes. Therefore, the shared state is shared between nodes and operations are not safe without using the Lock. The lock can be accessed via <code>shared.lock</code>.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>T</code> <p>The state of the graph.</p> required <code>shared</code> <code>S</code> <p>The shared state of the graph.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None. The instance references of the arguments are used in the graph to enable variance.</p> Source code in <code>src/edgygraph/nodes.py</code> <pre><code>@abstractmethod\nasync def __call__(self, state: T, shared: S) -&gt; None:\n    \"\"\"\n    Runs the node with the given state and shared state from the graph.\n\n    Operations on the state are merged in the graphs state after the node has finished.\n    Therefore, the state is not shared between nodes and operations are safe.\n\n    Operations on the shared state are reflected in all parallel running nodes.\n    Therefore, the shared state is shared between nodes and operations are not safe without using the Lock.\n    The lock can be accessed via `shared.lock`.\n\n    Args:\n        state: The state of the graph.\n        shared: The shared state of the graph.\n\n    Returns:\n        None. The instance references of the arguments are used in the graph to enable variance.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/nodes/#src.edgygraph.nodes.START","title":"<code>START</code>","text":"<p>Represents a start node</p> Source code in <code>src/edgygraph/nodes.py</code> <pre><code>class START:\n    \"\"\"\n    Represents a start node\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/nodes/#src.edgygraph.nodes.END","title":"<code>END</code>","text":"<p>Represents an end node</p> Source code in <code>src/edgygraph/nodes.py</code> <pre><code>class END:\n    \"\"\"\n    Represents an end node\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/rich/","title":"Rich Representation Mixin","text":""},{"location":"api/rich/#src.edgygraph.rich.RichReprMixin","title":"<code>RichReprMixin</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Mixin to limit the length of values in the rich representation of a Pydantic model. This is useful for large objects that should not be displayed in their entirety in the rich representation.</p> <p>Set MAX_CHARS_PER_VALUE to the maximum number of characters to display for each value. If a value exceeds this limit, it will be displayed as <code>&lt;object of length: {len(str(value))}&gt;</code>.</p> Source code in <code>src/edgygraph/rich.py</code> <pre><code>class RichReprMixin(BaseModel):\n    \"\"\"\n    Mixin to limit the length of values in the rich representation of a Pydantic model.\n    This is useful for large objects that should not be displayed in their entirety in the rich representation.\n\n    Set MAX_CHARS_PER_VALUE to the maximum number of characters to display for each value.\n    If a value exceeds this limit, it will be displayed as ```&lt;object of length: {len(str(value))}&gt;```.\n    \"\"\"\n\n    MAX_CHARS_PER_VALUE: int = Field(default=2000, exclude=True)\n\n    def __rich_repr__(self):\n\n        for name, field_info in self.__class__.model_fields.items():\n\n            if field_info.exclude:\n                continue\n\n            value = getattr(self, name)\n            length = len(str(value))\n\n            if length &gt; self.MAX_CHARS_PER_VALUE:\n                yield name, f\"&lt;object of length: {len(str(value))}&gt;\"\n            else:\n                yield name, value\n</code></pre>"},{"location":"api/states/","title":"States","text":""},{"location":"api/states/#src.edgygraph.states.PydanticModel","title":"<code>PydanticModel</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Minimal Protocol for Pydantic BaseModel Operations</p> Source code in <code>src/edgygraph/states.py</code> <pre><code>@runtime_checkable\nclass PydanticModel(Protocol):\n    \"\"\"Minimal Protocol for Pydantic BaseModel Operations\"\"\"\n\n    def model_dump(self) -&gt; dict[str, Any]: ...\n\n    def model_copy(self, *, update: Mapping[str, Any] | None = None, deep: bool = False) -&gt; Self: ...\n\n    @classmethod\n    def model_validate(cls, obj: Any) -&gt; Self: ...\n</code></pre>"},{"location":"api/states/#src.edgygraph.states.StateProtocol","title":"<code>StateProtocol</code>","text":"<p>               Bases: <code>PydanticModel</code>, <code>Protocol</code></p> <p>Protocol of State.</p> <p>The protocol is used to define the type of the state that the node expects. The usage of protocols allows a more flexible approach to generic typing.</p> Source code in <code>src/edgygraph/states.py</code> <pre><code>@runtime_checkable\nclass StateProtocol(PydanticModel, Protocol):\n    \"\"\"\n    Protocol of State.\n\n    The protocol is used to define the type of the state that the node expects.\n    The usage of protocols allows a more flexible approach to generic typing.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/states/#src.edgygraph.states.SharedProtocol","title":"<code>SharedProtocol</code>","text":"<p>               Bases: <code>PydanticModel</code>, <code>Protocol</code></p> <p>Protocol of Shared.</p> <p>The protocol is used to define the type of the shared state that the node expects. The usage of protocols allows a more flexible approach to generic typing.</p> Source code in <code>src/edgygraph/states.py</code> <pre><code>@runtime_checkable\nclass SharedProtocol(PydanticModel, Protocol):\n    \"\"\"\n    Protocol of Shared.\n\n    The protocol is used to define the type of the shared state that the node expects.\n    The usage of protocols allows a more flexible approach to generic typing.\n    \"\"\"\n    lock: Lock\n</code></pre>"},{"location":"api/states/#src.edgygraph.states.State","title":"<code>State</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Holds variables for the nodes of serializable types. Arbitrary types are not allowed.</p> <p>The state is copied for each parallel node and merged after the node has finished. Therefore, the state is not shared between nodes and operations are safe.</p> <p>Parallel changes of the same variable will be detected as a conflict and raise an error.</p> <p>Implements pydantic's BaseModel.</p> Source code in <code>src/edgygraph/states.py</code> <pre><code>class State(BaseModel):\n    \"\"\"\n    Holds variables for the nodes of serializable types. Arbitrary types are not allowed.\n\n    The state is copied for each parallel node and merged after the node has finished.\n    Therefore, the state is not shared between nodes and operations are safe.\n\n    Parallel changes of the same variable will be detected as a conflict and raise an error.\n\n    Implements pydantic's BaseModel.\n    \"\"\"\n    model_config = ConfigDict(arbitrary_types_allowed=False) # for deep copy\n</code></pre>"},{"location":"api/states/#src.edgygraph.states.Shared","title":"<code>Shared</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Holds shared variables for the nodes of any type.</p> <p>The shared state is shared between all parallel nodes and operations are not safe without using the Lock. The lock can be accessed via <code>shared.lock</code>.</p> <p>Implements pydantic's BaseModel with arbitrary types allowed.</p> Source code in <code>src/edgygraph/states.py</code> <pre><code>class Shared(BaseModel):\n    \"\"\"\n    Holds shared variables for the nodes of any type.\n\n    The shared state is shared between all parallel nodes and operations are not safe without using the Lock.\n    The lock can be accessed via `shared.lock`.\n\n    Implements pydantic's BaseModel with arbitrary types allowed.\n    \"\"\"\n    lock: Lock = Field(default_factory=Lock)\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"api/states/#src.edgygraph.states.StateAttribute","title":"<code>StateAttribute</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Holds variables of serializable types for the nodes. Arbitrary types are not allowed.</p> <p>Simplifies composition in states.</p> Source code in <code>src/edgygraph/states.py</code> <pre><code>class StateAttribute(BaseModel):\n    \"\"\"\n    Holds variables of serializable types for the nodes. Arbitrary types are not allowed.\n\n    Simplifies composition in states.\n    \"\"\"\n    model_config = ConfigDict(arbitrary_types_allowed=False) # for deep copy\n</code></pre>"},{"location":"api/states/#src.edgygraph.states.SharedAttribute","title":"<code>SharedAttribute</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Holds shared variables of any type for the nodes.</p> <p>Simplifies composition in shared states.</p> Source code in <code>src/edgygraph/states.py</code> <pre><code>class SharedAttribute(BaseModel):\n    \"\"\"\n    Holds shared variables of any type for the nodes.\n\n    Simplifies composition in shared states.\n    \"\"\"\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"api/states/#src.edgygraph.states.Stream","title":"<code>Stream</code>","text":"<p>               Bases: <code>ABC</code>, <code>AsyncIterator[T]</code></p> <p>Standardized wrapper interface for streams of data.</p> <p>Set the type of the data that the stream will yield with the generic type parameter <code>T</code>.</p> <p>Implements an async iterator and async context manager.</p> Source code in <code>src/edgygraph/states.py</code> <pre><code>class Stream[T: object](ABC, AsyncIterator[T]):\n    \"\"\"\n    Standardized wrapper interface for streams of data.\n\n    Set the type of the data that the stream will yield with the generic type parameter `T`.\n\n    Implements an async iterator and async context manager.\n    \"\"\"\n\n    @abstractmethod\n    async def aclose(self) -&gt; None:\n        pass\n\n    @abstractmethod\n    async def __anext__(self) -&gt; T:\n        pass\n\n    async def __aenter__(self) -&gt; \"Stream[T]\":\n        return self\n\n    async def __aexit__(\n            self, exc_type: type[BaseException] | None, \n            exc: BaseException | None, \n            tb: TracebackType | None\n        ) -&gt; None: # Not handling exceptions here -&gt; returns None\n\n        await self.aclose()\n</code></pre>"},{"location":"api/graph/branches/","title":"Branches","text":""},{"location":"api/graph/branches/#src.edgygraph.graph.branches.Branch","title":"<code>Branch</code>","text":"<p>A branch of the graph.</p> <p>Parameters:</p> Name Type Description Default <code>edges</code> <code>Sequence[Edge[T, S] | ErrorEdge[T, S] | NodeTupel[T, S]]</code> <p>The edges of the branch.</p> required <code>join</code> <code>Join[T, S]</code> <p>The node to join the branch after execution. If None the branch will not be joined.</p> <code>None</code> Source code in <code>src/edgygraph/graph/branches.py</code> <pre><code>class Branch[T: StateProtocol, S: SharedProtocol]:\n    \"\"\"\n    A branch of the graph.\n\n\n    Args:\n        edges: The edges of the branch.\n        join: The node to join the branch after execution. If None the branch will not be joined.\n\n    \"\"\"\n\n\n    def __init__(self, edges: Sequence[Edge[T, S] | ErrorEdge[T, S] | NodeTupel[T, S]], start: SingleSource[T, S], join: Join[T, S] = None) -&gt; None:\n\n        self.edges = edges\n        self.start = start\n        self.join = join\n\n        self.result: asyncio.Future[dict[tuple[Hashable, ...], Change]] | None = None\n\n        self.edge_index: dict[SingleSource[T, S], list[Entry[T, S]]] = defaultdict(list)\n        self.error_edge_index: dict[SingleErrorSource[T, S], list[ErrorEntry[T, S]]] = defaultdict(list)\n\n        self.index_edges()\n\n\n    def index_edges(self) -&gt; None:\n        \"\"\"\n        Index the edges by single source.\n\n        Append the edges to\n        - `edge_index` if the edge is a normal edge\n        - `error_edge_index` if the edge is an error edge\n        \"\"\"\n\n        for i, edge in enumerate(self.edges):\n\n            # Node Sequence\n            if Types[T, S].is_node_tupel(edge):\n\n                for source, next in zip(edge, edge[1:]):\n                    assert Types[T, S].is_single_source(source), f\"Unexpected source type in node sequence: {source}\"\n                    assert Types[T, S].is_next(next), f\"Unexpected next type in node sequence: {next}\"\n                    self.edge_index[source].append(Entry[T, S](next=next, config=Config(), index=i))\n\n                continue\n\n            match edge:\n                case (source, next, config): pass\n                case (source, next): config = None\n                case _: raise ValueError(f\"Invalid edge format: {edge}\")\n\n            if Types[T, S].is_error_source(source):\n                config = config or ErrorConfig()\n                assert isinstance(config, ErrorConfig), f\"Unexpected properties type for error edge {edge}: {config}\"\n\n                if Types[T, S].is_single_error_source(source):\n                    self.error_edge_index[source].append(ErrorEntry[T, S](next=next, config=config, index=i))\n                elif Types[T, S].is_single_error_source_sequence(source):\n                    for single_error_source in source:\n                        self.error_edge_index[single_error_source].append(ErrorEntry[T, S](next=next, config=config, index=i))\n                else:\n                    raise ValueError(f\"Invalid error source: {source}\")\n\n            elif Types[T, S].is_source(source):\n                config = config or Config()\n                assert isinstance(config, Config), f\"Unexpected properties type for node edge {edge}: {config}\"\n\n                if Types[T, S].is_single_source(source):\n                    self.edge_index[source].append(Entry[T, S](next=next, config=config, index=i))\n                elif Types[T, S].is_single_source_sequence(source):\n                    for single_source in source:\n                        self.edge_index[single_source].append(Entry[T, S](next=next, config=config, index=i))\n                else:\n                    raise ValueError(f\"Invalid source: {source}\")\n\n            else:\n                raise ValueError(f\"Invalid edge source: {edge[0]}\")\n</code></pre>"},{"location":"api/graph/branches/#src.edgygraph.graph.branches.Branch.index_edges","title":"<code>index_edges()</code>","text":"<p>Index the edges by single source.</p> <p>Append the edges to - <code>edge_index</code> if the edge is a normal edge - <code>error_edge_index</code> if the edge is an error edge</p> Source code in <code>src/edgygraph/graph/branches.py</code> <pre><code>def index_edges(self) -&gt; None:\n    \"\"\"\n    Index the edges by single source.\n\n    Append the edges to\n    - `edge_index` if the edge is a normal edge\n    - `error_edge_index` if the edge is an error edge\n    \"\"\"\n\n    for i, edge in enumerate(self.edges):\n\n        # Node Sequence\n        if Types[T, S].is_node_tupel(edge):\n\n            for source, next in zip(edge, edge[1:]):\n                assert Types[T, S].is_single_source(source), f\"Unexpected source type in node sequence: {source}\"\n                assert Types[T, S].is_next(next), f\"Unexpected next type in node sequence: {next}\"\n                self.edge_index[source].append(Entry[T, S](next=next, config=Config(), index=i))\n\n            continue\n\n        match edge:\n            case (source, next, config): pass\n            case (source, next): config = None\n            case _: raise ValueError(f\"Invalid edge format: {edge}\")\n\n        if Types[T, S].is_error_source(source):\n            config = config or ErrorConfig()\n            assert isinstance(config, ErrorConfig), f\"Unexpected properties type for error edge {edge}: {config}\"\n\n            if Types[T, S].is_single_error_source(source):\n                self.error_edge_index[source].append(ErrorEntry[T, S](next=next, config=config, index=i))\n            elif Types[T, S].is_single_error_source_sequence(source):\n                for single_error_source in source:\n                    self.error_edge_index[single_error_source].append(ErrorEntry[T, S](next=next, config=config, index=i))\n            else:\n                raise ValueError(f\"Invalid error source: {source}\")\n\n        elif Types[T, S].is_source(source):\n            config = config or Config()\n            assert isinstance(config, Config), f\"Unexpected properties type for node edge {edge}: {config}\"\n\n            if Types[T, S].is_single_source(source):\n                self.edge_index[source].append(Entry[T, S](next=next, config=config, index=i))\n            elif Types[T, S].is_single_source_sequence(source):\n                for single_source in source:\n                    self.edge_index[single_source].append(Entry[T, S](next=next, config=config, index=i))\n            else:\n                raise ValueError(f\"Invalid source: {source}\")\n\n        else:\n            raise ValueError(f\"Invalid edge source: {edge[0]}\")\n</code></pre>"},{"location":"api/graph/graphs/","title":"Graphs","text":""},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph","title":"<code>Graph</code>","text":"<p>Create and execute a graph defined by a list of edges</p>"},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph--generic-typing-parameters","title":"Generic Typing Parameters","text":"<p>Use protocols or classes that extend StateProtocol and SharedProtocol or State and Shared to define the supported state types.</p>"},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph--inheritance-with-variance","title":"Inheritance with Variance","text":"<p>With covariance its possible to use nodes that use more specific State and Shared classes as the generic typing parameters. Requires an inheritance structure.</p> <p>This is recommended for smaller projects because it needs less boilerplate.</p>"},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph--duck-typing","title":"Duck Typing","text":"<p>For the more flexible approach with better scaling use protocols to define the supported state types. Remember to always extend <code>typing.Protocol</code> in the child classes for typing.</p> <p>This is recommended for scalable projects where many different state types need to be joined in one graph. See edgynodes for an example.</p>"},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph--disable-type-checking","title":"Disable Type Checking","text":"<p>If you want to disable type checking for the graph, you can use <code>typing.Any</code> as generic typing parameters in the graph.</p>"},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph--edges","title":"Edges","text":"<p>The edges are defined as a list of tuples, where the first element is the source and the second element reveals the next node.</p>"},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph--branches","title":"Branches","text":"<p>The edges are contained in branches. A branch is a tuple with edges and a join parameter at the end. </p>"},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph--spawning","title":"Spawning","text":"<p>A branch is spawned when the source of the first edge of the branch is triggered.</p> <p>In this example it would be on <code>START</code>:</p> <pre><code>edges=[(\n   (START, node1),\n   (node1, node2),\n   END\n)]\n</code></pre> <p>In this example it would be on <code>node1</code> and on <code>node2</code> each:</p> <pre><code>edges=[(\n   ([node1, node2], node3),\n   node4\n)]\n</code></pre>"},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph--joining","title":"Joining","text":"<p>The join parameter can be of the following types:</p> <ul> <li><code>None</code>: The branch will not be joined.</li> <li><code>END</code>: The branch will be joined at the end of the graph.</li> <li>A node instance: The branch will be joined directly before the given node is executed in any branch into this branch.</li> </ul> <p>The process of joining describes waiting for the branches to finish wich aim to join and then applying the changes to the state of the whole finished branch to the state of the joining branch.</p>"},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph--formats","title":"Formats","text":"<p>A branch supports different formats for the edges.</p> <ul> <li><code>(source, target)</code>: A single edge from source to target.</li> <li><code>(START, target)</code>: A single edge from the start of the graph to target.</li> <li><code>(source, None)</code>: A single edge from source to no target. <code>END</code> is not allowed here, since it would be redundant. It is only allowed in join parameters to distinct join at the end of the graph (<code>END</code>) from not joining (<code>None</code>)</li> <li><code>([source1, source2], target)</code>: Multiple edges from source1 and source2 to target.</li> <li><code>(source, [target1, target2])</code>: Multiple edges from source to target1 and target2.</li> <li><code>([source1, source2], [target1, target2])</code>: Multiple edges from source1 and source2 to target1 and target2. This will create 4 edges in total.</li> <li><code>(source, lambda st, sh: [target1, target2] if sh.x)</code>: A dynamic edge from source to target. The function takes the state and the shared state as arguments. It must return a node, a list of nodes, END or None. Async functions are also supported. They are executed sequentially so there are no race conditions.</li> <li><code>(source, target, Config(instant=True))</code>: An instant edge from source to target. The target nodes are collected recursively and executed parallel to the source node. Make sure not to create cycles.</li> <li><code>(ValueError, target)</code>: An error edge from ValueError to target. The edge is traversed if a node, which is executed by an incoming edge located BEFORE this error edge in the edge list, throws a ValueError.</li> <li><code>((source, Exception), target)</code>: An error edge from Exception to target. The edge is traversed if the source node is executed by an incoming edge which is located BEFORE this error edge in the edge list throws an Exception. Source node lists are also supported.</li> <li><code>(Exception, target, ErrorConfig(propagate=True))</code>: If propagate is <code>True</code>, the exception is propagated to the next error edges in the edge list. If the exception is not handled by any error edge, it is ultimately raised.</li> </ul> <p>Attributes:</p> Name Type Description <code>edges</code> <p>A list of edges of compatible nodes that build the graph.</p> <code>hooks</code> <p>A list of graph hook classes. Usable for debugging, logging and custom logic.</p> Source code in <code>src/edgygraph/graph/graphs.py</code> <pre><code>class Graph[T: StateProtocol = StateProtocol, S: SharedProtocol = SharedProtocol]:\n    \"\"\"\n    Create and execute a graph defined by a list of edges\n\n\n    ## Generic Typing Parameters \n\n    Use protocols or classes that extend **StateProtocol** and **SharedProtocol** or **State** and **Shared** to define the supported state types.\n\n    ### Inheritance with Variance\n\n    With covariance its possible to use nodes that use more specific State and Shared classes as the generic typing parameters. Requires an inheritance structure.\n\n    This is recommended for smaller projects because it needs less boilerplate.\n\n    ### Duck Typing\n\n    For the more flexible approach with better scaling use protocols to define the supported state types. Remember to always extend `typing.Protocol` in the child classes for typing.\n\n    This is recommended for scalable projects where many different state types need to be joined in one graph. See [edgynodes](https://github.com/mathisxy/edgynodes/) for an example.\n\n    ### Disable Type Checking\n\n    If you want to disable type checking for the graph, you can use `typing.Any` as generic typing parameters in the graph.\n\n\n    ## Edges\n\n    The edges are defined as a list of tuples, where the first element is the source and the second element reveals the next node.\n\n    ### Branches\n\n    The edges are contained in branches. A branch is a tuple with edges and a join parameter at the end. \n\n    #### Spawning\n\n    A branch is spawned when the source of the first edge of the branch is triggered.\n\n    In this example it would be on `START`:\n\n    ```python\n    edges=[(\n       (START, node1),\n       (node1, node2),\n       END\n    )]\n    ```\n\n    In this example it would be on `node1` and on `node2` each:\n\n    ```python\n    edges=[(\n       ([node1, node2], node3),\n       node4\n    )]\n    ```\n\n    #### Joining\n\n    The join parameter can be of the following types:\n\n    - `None`: The branch will not be joined.\n    - `END`: The branch will be joined at the end of the graph.\n    - A node instance: The branch will be joined directly before the given node is executed in any branch into this branch.\n\n    The process of joining describes waiting for the branches to finish wich aim to join and then applying the changes to the state of the whole finished branch to the state of the joining branch.\n\n    ### Formats\n\n    A branch supports different formats for the edges.\n\n    - `(source, target)`: A single edge from source to target.\n    - `(START, target)`: A single edge from the start of the graph to target.\n    - `(source, None)`: A single edge from source to no target. `END` is not allowed here, since it would be redundant. It is only allowed in join parameters to distinct join at the end of the graph (`END`) from not joining (`None`)\n    - `([source1, source2], target)`: Multiple edges from source1 and source2 to target.\n    - `(source, [target1, target2])`: Multiple edges from source to target1 and target2.\n    - `([source1, source2], [target1, target2])`: Multiple edges from source1 and source2 to target1 and target2. This will create 4 edges in total.\n    - `(source, lambda st, sh: [target1, target2] if sh.x)`: A dynamic edge from source to target. The function takes the state and the shared state as arguments. It must return a node, a list of nodes, END or None. Async functions are also supported. They are executed sequentially so there are no race conditions.\n    - `(source, target, Config(instant=True))`: An instant edge from source to target. The target nodes are collected recursively and executed parallel to the source node. Make sure not to create cycles.\n    - `(ValueError, target)`: An error edge from ValueError to target. The edge is traversed if a node, which is executed by an incoming edge located BEFORE this error edge in the edge list, throws a ValueError.\n    - `((source, Exception), target)`: An error edge from Exception to target. The edge is traversed if the source node is executed by an incoming edge which is located BEFORE this error edge in the edge list throws an Exception. Source node lists are also supported.\n    - `(Exception, target, ErrorConfig(propagate=True))`: If propagate is `True`, the exception is propagated to the next error edges in the edge list. If the exception is not handled by any error edge, it is ultimately raised.\n\n\n    Attributes:\n        edges: A list of edges of compatible nodes that build the graph.\n        hooks: A list of graph hook classes. Usable for debugging, logging and custom logic.\n    \"\"\"\n\n\n    @property\n    def task_group(self) -&gt; asyncio.TaskGroup:\n        if self.tg is None:\n            raise RuntimeError(\"TaskGroup not initialized\")\n        return self.tg\n\n    tg: asyncio.TaskGroup | None = None\n\n\n    def __init__(self, \n            edges: Sequence[BranchContainer[T, S]], \n            hooks: Sequence[GraphHook[T, S]] | None = None\n        ) -&gt; None:\n\n        self.edges = edges\n        self.hooks = hooks or []\n\n        self.branch_registry: dict[SingleSource[T, S], list[Branch[T, S]]] = defaultdict(list)\n        self.join_registry: dict[Join[T, S], list[Branch[T, S]]] = defaultdict(list)\n\n        self.index_branches()\n\n    def index_branches(self) -&gt; None:\n        for branch_container in self.edges:\n\n            source = branch_container[0][0]\n\n            if Types[T, S].is_single_source(source):\n\n                branch = Branch[T, S](branch_container[:-1], source, branch_container[-1])\n                self.branch_registry[source].append(branch)\n\n            elif Types[T, S].is_single_source_sequence(source):\n\n                for start_node in source:\n\n                    branch = Branch[T, S](branch_container[:-1], start_node, branch_container[-1])\n                    self.branch_registry[start_node].append(branch)\n\n            else:\n                raise ValueError(f\"Invalid source type: {source}\")\n\n            print(self.branch_registry)\n\n\n    async def __call__(self, state: T, shared: S) -&gt; tuple[T, S]:\n        \"\"\"\n        Run the graph on the given state and shared state.\n        \"\"\"\n\n        # Hook\n        for h in self.hooks: await h.on_graph_start(state, shared)\n\n        async with asyncio.TaskGroup() as tg:\n\n            # Initialization\n            self.tg = tg\n\n            for branch in self.branch_registry[START]:\n                self.spawn_branch(state, shared, branch)\n\n        state_dict: dict[Hashable, Any] = cast(dict[Hashable, Any], state.model_dump())\n\n        for branch in self.join_registry[END]:\n\n            if branch.result is None:\n                raise ValueError(f\"Branch result is None: {branch}\")\n\n            changes = await branch.result\n\n            Diff.apply_changes(state_dict, changes)\n\n        # Final state\n        final_state = state.model_validate(state_dict)\n\n        # Hook\n        for h in self.hooks: await h.on_graph_end(final_state, shared)\n\n        return final_state, shared\n\n\n\n    async def run_branch(self, state: T, shared: S, branch: Branch[T, S]) -&gt; None:\n        \"\"\"\n        Execute the branch based on the edges\n\n        Args:\n            state: State of the first generic type of the graph or a subtype\n            shared: Shared of the second generic type of the graph or a subtype\n\n        Returns:\n            New State instance and the same Shared instance\n        \"\"\"\n\n        branch.result = asyncio.Future()\n\n        initial_state = state.model_copy(deep=True)\n\n        try:\n\n            next_nodes: list[NextNode[T, S]] = await self.get_next(state, shared, branch.start, branch)\n\n            print(\"INITIAL NEXT:\", next_nodes)\n\n\n            while next_nodes:\n\n                # Hook\n                for h in self.hooks: await h.on_step_start(state, shared, next_nodes)\n\n                # Run parallel\n                result_states: list[T] = []\n\n                await self.spawn_branches(state, shared, next_nodes)\n\n                state = await self.join_branches(state, next_nodes)\n\n                try:\n\n                    async with asyncio.TaskGroup() as tg:\n                        for node in next_nodes:\n\n                            state_copy: T = state.model_copy(deep=True)\n                            result_states.append(state_copy)\n\n                            tg.create_task(self.node_wrapper(state_copy, shared, node))\n\n                    # Merge\n                    state = await self.merge_states(state, result_states)\n\n\n                except ExceptionGroup as eg:\n\n                    print(\"ERROR\")\n                    print(eg)\n\n                    next_nodes = await self.get_next_from_error(state, shared, eg, branch)\n\n                    print(next_nodes)\n\n                else:\n\n                    next_nodes = await self.get_next(state, shared, [n.node for n in next_nodes], branch)\n\n                finally:\n\n                    # Hook\n                    for h in self.hooks: await h.on_step_end(state, shared, next_nodes)\n\n\n        except Exception as e:\n\n            # Hook\n            for h in self.hooks:\n                e = await h.on_error(e, state, shared)\n                if e is None: \n                    break\n\n            if e:\n                raise e\n\n        print(\" --- BRANCH RESULT --- \")\n\n        branch.result.set_result(Diff.recursive_diff(initial_state.model_dump(), state.model_dump()))\n\n\n\n    async def node_wrapper(self, state: T, shared: S, node: NextNode[T, S]):\n        \"\"\"\n        Wrapper for the nodes to catch exceptions and add the node to the exception with the key: `source_node`.\n\n        This is used to determine the node that caused the exception.\n        This is used in the `get_next_nodes_from_error` method to determine the next nodes to execute.\n\n        Args:\n            state: The state of the graph.\n            shared: The shared state of the graph.\n            node: The node to execute.\n        \"\"\"\n\n        try:\n            await node.node(state, shared)\n\n        except Exception as e:\n            e.source_node = node # type: ignore\n            raise e\n\n\n\n    async def merge_states(self, current_state: T, result_states: list[T]) -&gt; T:\n        \"\"\"\n        Merges the result states into the current state.\n        First the changes are calculated for each result state.\n        Then the changes are checked for conflicts.\n        If there are conflicts, a ChangeConflictException is raised.\n        The changes are applied in the order of the result states list.\n\n        Args:\n            current_state: The current state\n            result_states: The result states\n\n        Returns:\n            The new merged State instance.\n\n        Raises:\n            ChangeConflictException: If there are conflicts in the changes.\n        \"\"\"\n\n        result_dicts = [state.model_dump() for state in result_states]\n        current_dict = cast(dict[Hashable, Any], current_state.model_dump())\n\n        changes_list: list[dict[tuple[Hashable, ...], Change]] = []\n\n\n        for result_dict in result_dicts:\n\n            changes_list.append(Diff.recursive_diff(current_dict, result_dict))\n\n\n        # Hook\n        for h in self.hooks: await h.on_merge_start(current_state, result_states, changes_list)\n\n\n        state = await self.apply_changes(current_state, changes_list)\n\n\n        # Hook\n        for h in self.hooks: await h.on_merge_end(current_state, result_states, changes_list, state)\n\n        return state\n\n\n    async def apply_changes(self, state: T, changes: list[dict[tuple[Hashable, ...], Change]]) -&gt; T:\n        \"\"\"\n        Apply changes to the state.\n\n        Args:\n            state: The current state.\n            changes: A list of changes to apply.\n\n        Raises:\n            ChangeConflictException: If there are conflicts in the changes.\n        \"\"\"\n\n        state_dict = cast(dict[Hashable, Any], state.model_dump())\n        conflicts = Diff.find_conflicts(changes)\n\n        if conflicts:\n\n            # Hook\n            for h in self.hooks: await h.on_merge_conflict(state, changes, conflicts)\n\n            raise ChangeConflictException(f\"Conflicts detected: {conflicts}\")\n\n\n        for change in changes:\n            Diff.apply_changes(state_dict, change)\n\n        return type(state).model_validate(state_dict)\n\n\n    async def spawn_branches(self, state: T, shared: S, next_nodes: list[NextNode[T, S]]) -&gt; None:\n        \"\"\"\n        Spawn branches based on the next nodes.\n\n        Args:\n            state: The state of the graph.\n            next_nodes: The source nodes of the branches to execute.\n        \"\"\"\n\n        for node in next_nodes:\n            for branch in self.branch_registry[node.node]:\n\n                for h in self.hooks: await h.on_spawn_branch_start(state, shared, branch, node, self.branch_registry, self.join_registry)\n\n                self.spawn_branch(state, shared, branch)\n\n                for h in self.hooks: await h.on_spawn_branch_end(state, shared, branch, node, self.branch_registry, self.join_registry)\n\n\n\n    def spawn_branch(self, state: T, shared: S, branch: Branch[T, S]) -&gt; None:\n\n        self.join_registry[branch.join].append(branch)\n\n        self.task_group.create_task(self.run_branch(state, shared, branch))\n\n    async def join_branches(self, state: T, next_nodes: list[NextNode[T, S]]) -&gt; T:\n        \"\"\"\n        Join all branches that join on one of the next nodes.\n\n        Args:\n            state: The state of the graph.\n            next_nodes: The next nodes to execute.\n\n        Returns:\n            The merged state of the graph after joining the branches.\n        \"\"\"\n\n        changes: list[dict[tuple[Hashable, ...], Change]] = []\n\n        for node in next_nodes:\n            for branch in self.join_registry[node.node]:\n\n                if branch.result is None:\n                    raise ValueError(f\"Branch {branch} has no result\")\n\n                changes.append(await branch.result)\n\n                self.join_registry[node.node].remove(branch)\n\n        state = await self.apply_changes(state, changes)\n\n        return state\n\n\n\n    async def get_next(self, state: T, shared: S, current_nodes: Source[T, S], branch: Branch[T, S]) -&gt; list[NextNode[T, S]]:\n        \"\"\"\n        Get the next nodes to run based on the current nodes and the graph's edges.\n\n        Callable edges are called with the state and shared state.\n\n        Args:\n            state: The current state\n            shared: The shared state\n            current_nodes: The current nodes\n\n        Returns:\n           The list of the next nodes including their edges that they were reached by.\n        \"\"\"\n\n        print(f\"GET NEXT FOR CURRENT NODES: {current_nodes}\")\n\n        next_list: list[NextNode[T, S]] = []\n\n        if Types[T, S].is_single_source_sequence(current_nodes):\n            print(\"IS SINGLE SOURCE SEQUENCE\")\n            for current_node in current_nodes:\n                next_list.extend(\n                    await self.resolve_entries(state, shared, branch.edge_index[current_node])\n                )\n\n        elif Types[T, S].is_single_source(current_nodes):\n            print(\"IS SINGLE SOURCE\")\n            next_list.extend(\n                await self.resolve_entries(state, shared, branch.edge_index[current_nodes])\n            )\n\n        else:\n            raise ValueError(f\"Invalid current_nodes type: {type(current_nodes)}\")\n\n\n        # Instant nodes\n        current_instant_next_list: list[NextNode[T, S]] = []\n\n        while True:\n\n            current_entries = [\n                entry\n                for next in current_instant_next_list \n                for entry in branch.edge_index[next.node]\n                if entry.config.instant\n            ]\n\n            if not current_entries:\n                break\n\n            current_instant_next_list = await self.resolve_entries(state, shared, current_entries)\n            next_list.extend(current_instant_next_list)\n\n\n        return next_list\n\n\n\n    async def get_next_from_error(self, state: T, shared: S, eg: ExceptionGroup, branch: Branch[T, S]) -&gt; list[NextNode[T, S]]:\n        \"\"\"\n        Get the next nodes to execute from the error.\n\n        If exceptions in the group dont have the key `source_node` they will be reraised as an Exception group.\n\n        Args:\n            state: The state of the graph.\n            shared: The shared state of the graph.\n            eg: The exception group with all errors to get the next nodes from.\n\n        Returns:\n            The next nodes to execute.\n        \"\"\"\n\n        next_nodes: list[NextNode[T, S]] = []\n        unhandled: list[Exception] = []\n\n        for e in eg.exceptions:\n\n            print(e)\n\n\n            source_node: NextNode[T, S] | None = getattr(e, \"source_node\", None)\n\n            if not isinstance(source_node, NextNode):\n                unhandled.append(e)\n                continue\n\n            entries: list[ErrorEntry[T, S]] = []\n\n            for key in branch.error_edge_index.keys():\n\n                if self.match_error(e, key, source_node):\n                    entries.extend(branch.error_edge_index[key])\n\n            entries.sort(key=lambda x: x.index)\n            for entry in entries:\n                if entry.index &gt; source_node.reached_by.index: # If the error entry is after the node that raised the error\n                    next_nodes.extend(\n                        await self.resolve_entries(state, shared, [entry])\n                    )\n\n                    print(entry)\n                    if not entry.config.propagate:\n                        break\n            else: # Not consumed\n                unhandled.append(e)\n\n\n        if unhandled:\n            raise ExceptionGroup(\"Unhandled node exceptions\", unhandled)\n\n        return next_nodes\n\n\n\n    def match_error(self, e: Exception, source: SingleErrorSource[T, S], source_node: NextNode[T, S]) -&gt; bool:\n\n        match source:\n            case type(): # Exception type\n                return issubclass(type(e), source)\n            case (node, error_type): # (Node, Exception type)\n                return node == source_node.node and isinstance(e, error_type)\n\n\n    async def resolve_entries(self, state: T, shared: S, entries: Sequence[Entries[T, S]]) -&gt; list[NextNode[T, S]]:\n\n        print(f\"RESOLVE: {entries}\")\n\n        return [\n            next_node\n            for entry in entries\n            for next_node in await self.resolve_entry(state, shared, entry)\n        ]\n\n\n    async def resolve_entry(self, state: T, shared: S, entry: Entries[T, S]) -&gt; list[NextNode[T, S]]:\n        \"\"\"\n        Resolve the next to nodes.\n\n        Make sure to ONLY call this method ONCE per execution of the corresponding edge.\n\n        Args:\n            state: The current state.\n            shared: The shared state.\n\n        Returns:\n            The resolved nodes.\n        \"\"\"\n\n        print(f\"RESOLVING: {entry}\")\n\n        next = entry.next\n\n\n\n        if not Types[T, S].is_resolved_next(next):\n            print(\"CALLABLE\")\n            next = cast(Callable[[T, S], ResolvedNext[T, S]], next)\n            next = next(state, shared)\n\n            if inspect.isawaitable(next):\n                next = await next\n\n\n        return [\n            NextNode[T, S](node=node, reached_by=entry)\n            for node in self.get_next_nodes(next)\n        ]\n\n\n\n    def get_next_nodes(self, next: ResolvedNext[T, S]) -&gt; list[Node[T, S]]:\n\n        next_nodes: list[Node[T, S]] = []\n\n        def match(x: SingleNext[T, S]) -&gt; None:\n\n            match x:\n\n                case None:\n                    print(\"None\")\n                    pass\n\n                case Node():\n                    print(\"Node\")\n                    next_nodes.append(x)\n\n\n        if Types[T, S].is_single_next_sequence(next):\n            print(\"Sequence\")\n            for x in next:\n                match(x)\n\n        elif Types[T, S].is_single_next(next):\n            print(\"Single\")\n            match(next)\n\n        return next_nodes\n</code></pre>"},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph.__call__","title":"<code>__call__(state, shared)</code>  <code>async</code>","text":"<p>Run the graph on the given state and shared state.</p> Source code in <code>src/edgygraph/graph/graphs.py</code> <pre><code>async def __call__(self, state: T, shared: S) -&gt; tuple[T, S]:\n    \"\"\"\n    Run the graph on the given state and shared state.\n    \"\"\"\n\n    # Hook\n    for h in self.hooks: await h.on_graph_start(state, shared)\n\n    async with asyncio.TaskGroup() as tg:\n\n        # Initialization\n        self.tg = tg\n\n        for branch in self.branch_registry[START]:\n            self.spawn_branch(state, shared, branch)\n\n    state_dict: dict[Hashable, Any] = cast(dict[Hashable, Any], state.model_dump())\n\n    for branch in self.join_registry[END]:\n\n        if branch.result is None:\n            raise ValueError(f\"Branch result is None: {branch}\")\n\n        changes = await branch.result\n\n        Diff.apply_changes(state_dict, changes)\n\n    # Final state\n    final_state = state.model_validate(state_dict)\n\n    # Hook\n    for h in self.hooks: await h.on_graph_end(final_state, shared)\n\n    return final_state, shared\n</code></pre>"},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph.run_branch","title":"<code>run_branch(state, shared, branch)</code>  <code>async</code>","text":"<p>Execute the branch based on the edges</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>T</code> <p>State of the first generic type of the graph or a subtype</p> required <code>shared</code> <code>S</code> <p>Shared of the second generic type of the graph or a subtype</p> required <p>Returns:</p> Type Description <code>None</code> <p>New State instance and the same Shared instance</p> Source code in <code>src/edgygraph/graph/graphs.py</code> <pre><code>async def run_branch(self, state: T, shared: S, branch: Branch[T, S]) -&gt; None:\n    \"\"\"\n    Execute the branch based on the edges\n\n    Args:\n        state: State of the first generic type of the graph or a subtype\n        shared: Shared of the second generic type of the graph or a subtype\n\n    Returns:\n        New State instance and the same Shared instance\n    \"\"\"\n\n    branch.result = asyncio.Future()\n\n    initial_state = state.model_copy(deep=True)\n\n    try:\n\n        next_nodes: list[NextNode[T, S]] = await self.get_next(state, shared, branch.start, branch)\n\n        print(\"INITIAL NEXT:\", next_nodes)\n\n\n        while next_nodes:\n\n            # Hook\n            for h in self.hooks: await h.on_step_start(state, shared, next_nodes)\n\n            # Run parallel\n            result_states: list[T] = []\n\n            await self.spawn_branches(state, shared, next_nodes)\n\n            state = await self.join_branches(state, next_nodes)\n\n            try:\n\n                async with asyncio.TaskGroup() as tg:\n                    for node in next_nodes:\n\n                        state_copy: T = state.model_copy(deep=True)\n                        result_states.append(state_copy)\n\n                        tg.create_task(self.node_wrapper(state_copy, shared, node))\n\n                # Merge\n                state = await self.merge_states(state, result_states)\n\n\n            except ExceptionGroup as eg:\n\n                print(\"ERROR\")\n                print(eg)\n\n                next_nodes = await self.get_next_from_error(state, shared, eg, branch)\n\n                print(next_nodes)\n\n            else:\n\n                next_nodes = await self.get_next(state, shared, [n.node for n in next_nodes], branch)\n\n            finally:\n\n                # Hook\n                for h in self.hooks: await h.on_step_end(state, shared, next_nodes)\n\n\n    except Exception as e:\n\n        # Hook\n        for h in self.hooks:\n            e = await h.on_error(e, state, shared)\n            if e is None: \n                break\n\n        if e:\n            raise e\n\n    print(\" --- BRANCH RESULT --- \")\n\n    branch.result.set_result(Diff.recursive_diff(initial_state.model_dump(), state.model_dump()))\n</code></pre>"},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph.node_wrapper","title":"<code>node_wrapper(state, shared, node)</code>  <code>async</code>","text":"<p>Wrapper for the nodes to catch exceptions and add the node to the exception with the key: <code>source_node</code>.</p> <p>This is used to determine the node that caused the exception. This is used in the <code>get_next_nodes_from_error</code> method to determine the next nodes to execute.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>T</code> <p>The state of the graph.</p> required <code>shared</code> <code>S</code> <p>The shared state of the graph.</p> required <code>node</code> <code>NextNode[T, S]</code> <p>The node to execute.</p> required Source code in <code>src/edgygraph/graph/graphs.py</code> <pre><code>async def node_wrapper(self, state: T, shared: S, node: NextNode[T, S]):\n    \"\"\"\n    Wrapper for the nodes to catch exceptions and add the node to the exception with the key: `source_node`.\n\n    This is used to determine the node that caused the exception.\n    This is used in the `get_next_nodes_from_error` method to determine the next nodes to execute.\n\n    Args:\n        state: The state of the graph.\n        shared: The shared state of the graph.\n        node: The node to execute.\n    \"\"\"\n\n    try:\n        await node.node(state, shared)\n\n    except Exception as e:\n        e.source_node = node # type: ignore\n        raise e\n</code></pre>"},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph.merge_states","title":"<code>merge_states(current_state, result_states)</code>  <code>async</code>","text":"<p>Merges the result states into the current state. First the changes are calculated for each result state. Then the changes are checked for conflicts. If there are conflicts, a ChangeConflictException is raised. The changes are applied in the order of the result states list.</p> <p>Parameters:</p> Name Type Description Default <code>current_state</code> <code>T</code> <p>The current state</p> required <code>result_states</code> <code>list[T]</code> <p>The result states</p> required <p>Returns:</p> Type Description <code>T</code> <p>The new merged State instance.</p> <p>Raises:</p> Type Description <code>ChangeConflictException</code> <p>If there are conflicts in the changes.</p> Source code in <code>src/edgygraph/graph/graphs.py</code> <pre><code>async def merge_states(self, current_state: T, result_states: list[T]) -&gt; T:\n    \"\"\"\n    Merges the result states into the current state.\n    First the changes are calculated for each result state.\n    Then the changes are checked for conflicts.\n    If there are conflicts, a ChangeConflictException is raised.\n    The changes are applied in the order of the result states list.\n\n    Args:\n        current_state: The current state\n        result_states: The result states\n\n    Returns:\n        The new merged State instance.\n\n    Raises:\n        ChangeConflictException: If there are conflicts in the changes.\n    \"\"\"\n\n    result_dicts = [state.model_dump() for state in result_states]\n    current_dict = cast(dict[Hashable, Any], current_state.model_dump())\n\n    changes_list: list[dict[tuple[Hashable, ...], Change]] = []\n\n\n    for result_dict in result_dicts:\n\n        changes_list.append(Diff.recursive_diff(current_dict, result_dict))\n\n\n    # Hook\n    for h in self.hooks: await h.on_merge_start(current_state, result_states, changes_list)\n\n\n    state = await self.apply_changes(current_state, changes_list)\n\n\n    # Hook\n    for h in self.hooks: await h.on_merge_end(current_state, result_states, changes_list, state)\n\n    return state\n</code></pre>"},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph.apply_changes","title":"<code>apply_changes(state, changes)</code>  <code>async</code>","text":"<p>Apply changes to the state.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>T</code> <p>The current state.</p> required <code>changes</code> <code>list[dict[tuple[Hashable, ...], Change]]</code> <p>A list of changes to apply.</p> required <p>Raises:</p> Type Description <code>ChangeConflictException</code> <p>If there are conflicts in the changes.</p> Source code in <code>src/edgygraph/graph/graphs.py</code> <pre><code>async def apply_changes(self, state: T, changes: list[dict[tuple[Hashable, ...], Change]]) -&gt; T:\n    \"\"\"\n    Apply changes to the state.\n\n    Args:\n        state: The current state.\n        changes: A list of changes to apply.\n\n    Raises:\n        ChangeConflictException: If there are conflicts in the changes.\n    \"\"\"\n\n    state_dict = cast(dict[Hashable, Any], state.model_dump())\n    conflicts = Diff.find_conflicts(changes)\n\n    if conflicts:\n\n        # Hook\n        for h in self.hooks: await h.on_merge_conflict(state, changes, conflicts)\n\n        raise ChangeConflictException(f\"Conflicts detected: {conflicts}\")\n\n\n    for change in changes:\n        Diff.apply_changes(state_dict, change)\n\n    return type(state).model_validate(state_dict)\n</code></pre>"},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph.spawn_branches","title":"<code>spawn_branches(state, shared, next_nodes)</code>  <code>async</code>","text":"<p>Spawn branches based on the next nodes.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>T</code> <p>The state of the graph.</p> required <code>next_nodes</code> <code>list[NextNode[T, S]]</code> <p>The source nodes of the branches to execute.</p> required Source code in <code>src/edgygraph/graph/graphs.py</code> <pre><code>async def spawn_branches(self, state: T, shared: S, next_nodes: list[NextNode[T, S]]) -&gt; None:\n    \"\"\"\n    Spawn branches based on the next nodes.\n\n    Args:\n        state: The state of the graph.\n        next_nodes: The source nodes of the branches to execute.\n    \"\"\"\n\n    for node in next_nodes:\n        for branch in self.branch_registry[node.node]:\n\n            for h in self.hooks: await h.on_spawn_branch_start(state, shared, branch, node, self.branch_registry, self.join_registry)\n\n            self.spawn_branch(state, shared, branch)\n\n            for h in self.hooks: await h.on_spawn_branch_end(state, shared, branch, node, self.branch_registry, self.join_registry)\n</code></pre>"},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph.join_branches","title":"<code>join_branches(state, next_nodes)</code>  <code>async</code>","text":"<p>Join all branches that join on one of the next nodes.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>T</code> <p>The state of the graph.</p> required <code>next_nodes</code> <code>list[NextNode[T, S]]</code> <p>The next nodes to execute.</p> required <p>Returns:</p> Type Description <code>T</code> <p>The merged state of the graph after joining the branches.</p> Source code in <code>src/edgygraph/graph/graphs.py</code> <pre><code>async def join_branches(self, state: T, next_nodes: list[NextNode[T, S]]) -&gt; T:\n    \"\"\"\n    Join all branches that join on one of the next nodes.\n\n    Args:\n        state: The state of the graph.\n        next_nodes: The next nodes to execute.\n\n    Returns:\n        The merged state of the graph after joining the branches.\n    \"\"\"\n\n    changes: list[dict[tuple[Hashable, ...], Change]] = []\n\n    for node in next_nodes:\n        for branch in self.join_registry[node.node]:\n\n            if branch.result is None:\n                raise ValueError(f\"Branch {branch} has no result\")\n\n            changes.append(await branch.result)\n\n            self.join_registry[node.node].remove(branch)\n\n    state = await self.apply_changes(state, changes)\n\n    return state\n</code></pre>"},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph.get_next","title":"<code>get_next(state, shared, current_nodes, branch)</code>  <code>async</code>","text":"<p>Get the next nodes to run based on the current nodes and the graph's edges.</p> <p>Callable edges are called with the state and shared state.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>T</code> <p>The current state</p> required <code>shared</code> <code>S</code> <p>The shared state</p> required <code>current_nodes</code> <code>Source[T, S]</code> <p>The current nodes</p> required <p>Returns:</p> Type Description <code>list[NextNode[T, S]]</code> <p>The list of the next nodes including their edges that they were reached by.</p> Source code in <code>src/edgygraph/graph/graphs.py</code> <pre><code>async def get_next(self, state: T, shared: S, current_nodes: Source[T, S], branch: Branch[T, S]) -&gt; list[NextNode[T, S]]:\n    \"\"\"\n    Get the next nodes to run based on the current nodes and the graph's edges.\n\n    Callable edges are called with the state and shared state.\n\n    Args:\n        state: The current state\n        shared: The shared state\n        current_nodes: The current nodes\n\n    Returns:\n       The list of the next nodes including their edges that they were reached by.\n    \"\"\"\n\n    print(f\"GET NEXT FOR CURRENT NODES: {current_nodes}\")\n\n    next_list: list[NextNode[T, S]] = []\n\n    if Types[T, S].is_single_source_sequence(current_nodes):\n        print(\"IS SINGLE SOURCE SEQUENCE\")\n        for current_node in current_nodes:\n            next_list.extend(\n                await self.resolve_entries(state, shared, branch.edge_index[current_node])\n            )\n\n    elif Types[T, S].is_single_source(current_nodes):\n        print(\"IS SINGLE SOURCE\")\n        next_list.extend(\n            await self.resolve_entries(state, shared, branch.edge_index[current_nodes])\n        )\n\n    else:\n        raise ValueError(f\"Invalid current_nodes type: {type(current_nodes)}\")\n\n\n    # Instant nodes\n    current_instant_next_list: list[NextNode[T, S]] = []\n\n    while True:\n\n        current_entries = [\n            entry\n            for next in current_instant_next_list \n            for entry in branch.edge_index[next.node]\n            if entry.config.instant\n        ]\n\n        if not current_entries:\n            break\n\n        current_instant_next_list = await self.resolve_entries(state, shared, current_entries)\n        next_list.extend(current_instant_next_list)\n\n\n    return next_list\n</code></pre>"},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph.get_next_from_error","title":"<code>get_next_from_error(state, shared, eg, branch)</code>  <code>async</code>","text":"<p>Get the next nodes to execute from the error.</p> <p>If exceptions in the group dont have the key <code>source_node</code> they will be reraised as an Exception group.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>T</code> <p>The state of the graph.</p> required <code>shared</code> <code>S</code> <p>The shared state of the graph.</p> required <code>eg</code> <code>ExceptionGroup</code> <p>The exception group with all errors to get the next nodes from.</p> required <p>Returns:</p> Type Description <code>list[NextNode[T, S]]</code> <p>The next nodes to execute.</p> Source code in <code>src/edgygraph/graph/graphs.py</code> <pre><code>async def get_next_from_error(self, state: T, shared: S, eg: ExceptionGroup, branch: Branch[T, S]) -&gt; list[NextNode[T, S]]:\n    \"\"\"\n    Get the next nodes to execute from the error.\n\n    If exceptions in the group dont have the key `source_node` they will be reraised as an Exception group.\n\n    Args:\n        state: The state of the graph.\n        shared: The shared state of the graph.\n        eg: The exception group with all errors to get the next nodes from.\n\n    Returns:\n        The next nodes to execute.\n    \"\"\"\n\n    next_nodes: list[NextNode[T, S]] = []\n    unhandled: list[Exception] = []\n\n    for e in eg.exceptions:\n\n        print(e)\n\n\n        source_node: NextNode[T, S] | None = getattr(e, \"source_node\", None)\n\n        if not isinstance(source_node, NextNode):\n            unhandled.append(e)\n            continue\n\n        entries: list[ErrorEntry[T, S]] = []\n\n        for key in branch.error_edge_index.keys():\n\n            if self.match_error(e, key, source_node):\n                entries.extend(branch.error_edge_index[key])\n\n        entries.sort(key=lambda x: x.index)\n        for entry in entries:\n            if entry.index &gt; source_node.reached_by.index: # If the error entry is after the node that raised the error\n                next_nodes.extend(\n                    await self.resolve_entries(state, shared, [entry])\n                )\n\n                print(entry)\n                if not entry.config.propagate:\n                    break\n        else: # Not consumed\n            unhandled.append(e)\n\n\n    if unhandled:\n        raise ExceptionGroup(\"Unhandled node exceptions\", unhandled)\n\n    return next_nodes\n</code></pre>"},{"location":"api/graph/graphs/#src.edgygraph.graph.graphs.Graph.resolve_entry","title":"<code>resolve_entry(state, shared, entry)</code>  <code>async</code>","text":"<p>Resolve the next to nodes.</p> <p>Make sure to ONLY call this method ONCE per execution of the corresponding edge.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>T</code> <p>The current state.</p> required <code>shared</code> <code>S</code> <p>The shared state.</p> required <p>Returns:</p> Type Description <code>list[NextNode[T, S]]</code> <p>The resolved nodes.</p> Source code in <code>src/edgygraph/graph/graphs.py</code> <pre><code>async def resolve_entry(self, state: T, shared: S, entry: Entries[T, S]) -&gt; list[NextNode[T, S]]:\n    \"\"\"\n    Resolve the next to nodes.\n\n    Make sure to ONLY call this method ONCE per execution of the corresponding edge.\n\n    Args:\n        state: The current state.\n        shared: The shared state.\n\n    Returns:\n        The resolved nodes.\n    \"\"\"\n\n    print(f\"RESOLVING: {entry}\")\n\n    next = entry.next\n\n\n\n    if not Types[T, S].is_resolved_next(next):\n        print(\"CALLABLE\")\n        next = cast(Callable[[T, S], ResolvedNext[T, S]], next)\n        next = next(state, shared)\n\n        if inspect.isawaitable(next):\n            next = await next\n\n\n    return [\n        NextNode[T, S](node=node, reached_by=entry)\n        for node in self.get_next_nodes(next)\n    ]\n</code></pre>"},{"location":"api/graph/hooks/","title":"Hooks","text":""},{"location":"api/graph/hooks/#src.edgygraph.graph.hooks.GraphHook","title":"<code>GraphHook</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Hook for the graph execution.</p> <p>Hooks are called at different stages of the graph execution. They can be used to log, modify the state, or perform other actions.</p> Source code in <code>src/edgygraph/graph/hooks.py</code> <pre><code>class GraphHook[T: StateProtocol, S: SharedProtocol](ABC):\n    \"\"\"\n    Hook for the graph execution.\n\n    Hooks are called at different stages of the graph execution.\n    They can be used to log, modify the state, or perform other actions.\n    \"\"\"\n\n    async def on_graph_start(self, state: T, shared: S) -&gt; None:\n        \"\"\"\n        Called when the graph starts.\n\n        Args:\n            state: The initial state of the graph.\n            shared: The initial shared state of the graph.\n        \"\"\"\n\n        pass\n\n\n    async def on_step_start(self, state: T, shared: S, nodes: list[NextNode[T, S]]) -&gt; None:\n        \"\"\"\n        Called when a step starts.\n\n        Args:\n            state: The state of the graph.\n            shared: The shared state of the graph.\n            nodes: The nodes that will be executed in this step.\n        \"\"\"\n\n        pass\n\n\n    async def on_step_end(self, state: T, shared: S, nodes: list[NextNode[T, S]]) -&gt; None:\n        \"\"\"\n        Called when a step ends.\n\n        It is called after all nodes have been executed and the state has been merged.\n\n        Args:\n            state: The updated state of the graph.\n            shared: The shared state of the graph.\n            nodes: The nodes that were executed in this step.\n        \"\"\"\n\n        pass\n\n\n    async def on_spawn_branch_start(self, state: T, shared: S, branch: Branch[T, S], trigger: NextNode[T, S], branch_registry: dict[SingleSource[T, S], list[Branch[T, S]]], join_registry: dict[Join[T, S], list[Branch[T, S]]]):\n        \"\"\"\n        Called before a branch is spawned.\n\n        Args:\n            state: The state of the graph.\n            shared: The shared state of the graph.\n            branch: The branch to be spawned.\n            branch_registry: The branch registry of the graph.\n            source_node: The node that spawned the branch.\n        \"\"\"\n\n        pass\n\n\n    async def on_spawn_branch_end(self, state: T, shared: S, branch: Branch[T, S], trigger: NextNode[T, S], branch_registry: dict[SingleSource[T, S], list[Branch[T, S]]], join_registry: dict[Join[T, S], list[Branch[T, S]]]):\n        \"\"\"\n        Called after a branch is spawned.\n\n        Args:\n            state: The state of the graph.\n            shared: The shared state of the graph.\n            branch: The branch that was spawned.\n            branch_registry: The branch registry of the graph.\n            trigger: The node that spawned the branch.\n        \"\"\"\n\n        pass\n\n\n\n    async def on_merge_start(self, state: T, result_states: list[T], changes: list[dict[tuple[Hashable, ...], Change]]) -&gt; None:\n        \"\"\"\n        Called when the merge process starts.\n\n        Args:\n            state: The old state of the graph.\n            result_states: The result states of the nodes.\n            changes: The changes that will be applied to the state.\n        \"\"\"\n\n        pass\n\n\n    async def on_merge_conflict(self, state: T, changes: list[dict[tuple[Hashable, ...], Change]], conflicts: dict[tuple[Hashable, ...], list[Change]]) -&gt; None:\n        \"\"\"\n        Called when a merge conflict occurs.\n\n        Args:\n            state: The old state of the graph.\n            changes: The changes that will be applied to the state.\n            conflicts: The conflicts that occurred during the merge process.\n        \"\"\"\n\n        pass\n\n\n    async def on_merge_end(self, state: T, result_states: list[T], changes: list[dict[tuple[Hashable, ...], Change]], merged_state: T) -&gt; None:\n        \"\"\"\n        Called when the merge process ends.\n\n        Args:\n            state: The old state of the graph.\n            result_states: The result states of the nodes.\n            changes: The changes that have been applied to the state.\n            merged_state: The new merged state of the graph.\n        \"\"\"\n\n        pass\n\n\n    async def on_graph_end(self, state: T, shared: S) -&gt; None:\n        \"\"\"\n        Called when the graph execution ends.\n\n        Args:\n            state: The final state of the graph.\n            shared: The final shared data.\n        \"\"\"\n\n        pass\n\n\n    async def on_error(self, error: Exception, state: T, shared: S) -&gt; Exception | None:\n        \"\"\"\n        Called when an error occurs during the graph execution.\n\n        Args:\n            error: The error that occurred.\n\n        Returns:\n           The error to raise, or None not to raise an error.\n        \"\"\"\n\n        return error\n</code></pre>"},{"location":"api/graph/hooks/#src.edgygraph.graph.hooks.GraphHook.on_graph_start","title":"<code>on_graph_start(state, shared)</code>  <code>async</code>","text":"<p>Called when the graph starts.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>T</code> <p>The initial state of the graph.</p> required <code>shared</code> <code>S</code> <p>The initial shared state of the graph.</p> required Source code in <code>src/edgygraph/graph/hooks.py</code> <pre><code>async def on_graph_start(self, state: T, shared: S) -&gt; None:\n    \"\"\"\n    Called when the graph starts.\n\n    Args:\n        state: The initial state of the graph.\n        shared: The initial shared state of the graph.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/graph/hooks/#src.edgygraph.graph.hooks.GraphHook.on_step_start","title":"<code>on_step_start(state, shared, nodes)</code>  <code>async</code>","text":"<p>Called when a step starts.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>T</code> <p>The state of the graph.</p> required <code>shared</code> <code>S</code> <p>The shared state of the graph.</p> required <code>nodes</code> <code>list[NextNode[T, S]]</code> <p>The nodes that will be executed in this step.</p> required Source code in <code>src/edgygraph/graph/hooks.py</code> <pre><code>async def on_step_start(self, state: T, shared: S, nodes: list[NextNode[T, S]]) -&gt; None:\n    \"\"\"\n    Called when a step starts.\n\n    Args:\n        state: The state of the graph.\n        shared: The shared state of the graph.\n        nodes: The nodes that will be executed in this step.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/graph/hooks/#src.edgygraph.graph.hooks.GraphHook.on_step_end","title":"<code>on_step_end(state, shared, nodes)</code>  <code>async</code>","text":"<p>Called when a step ends.</p> <p>It is called after all nodes have been executed and the state has been merged.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>T</code> <p>The updated state of the graph.</p> required <code>shared</code> <code>S</code> <p>The shared state of the graph.</p> required <code>nodes</code> <code>list[NextNode[T, S]]</code> <p>The nodes that were executed in this step.</p> required Source code in <code>src/edgygraph/graph/hooks.py</code> <pre><code>async def on_step_end(self, state: T, shared: S, nodes: list[NextNode[T, S]]) -&gt; None:\n    \"\"\"\n    Called when a step ends.\n\n    It is called after all nodes have been executed and the state has been merged.\n\n    Args:\n        state: The updated state of the graph.\n        shared: The shared state of the graph.\n        nodes: The nodes that were executed in this step.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/graph/hooks/#src.edgygraph.graph.hooks.GraphHook.on_spawn_branch_start","title":"<code>on_spawn_branch_start(state, shared, branch, trigger, branch_registry, join_registry)</code>  <code>async</code>","text":"<p>Called before a branch is spawned.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>T</code> <p>The state of the graph.</p> required <code>shared</code> <code>S</code> <p>The shared state of the graph.</p> required <code>branch</code> <code>Branch[T, S]</code> <p>The branch to be spawned.</p> required <code>branch_registry</code> <code>dict[SingleSource[T, S], list[Branch[T, S]]]</code> <p>The branch registry of the graph.</p> required <code>source_node</code> <p>The node that spawned the branch.</p> required Source code in <code>src/edgygraph/graph/hooks.py</code> <pre><code>async def on_spawn_branch_start(self, state: T, shared: S, branch: Branch[T, S], trigger: NextNode[T, S], branch_registry: dict[SingleSource[T, S], list[Branch[T, S]]], join_registry: dict[Join[T, S], list[Branch[T, S]]]):\n    \"\"\"\n    Called before a branch is spawned.\n\n    Args:\n        state: The state of the graph.\n        shared: The shared state of the graph.\n        branch: The branch to be spawned.\n        branch_registry: The branch registry of the graph.\n        source_node: The node that spawned the branch.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/graph/hooks/#src.edgygraph.graph.hooks.GraphHook.on_spawn_branch_end","title":"<code>on_spawn_branch_end(state, shared, branch, trigger, branch_registry, join_registry)</code>  <code>async</code>","text":"<p>Called after a branch is spawned.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>T</code> <p>The state of the graph.</p> required <code>shared</code> <code>S</code> <p>The shared state of the graph.</p> required <code>branch</code> <code>Branch[T, S]</code> <p>The branch that was spawned.</p> required <code>branch_registry</code> <code>dict[SingleSource[T, S], list[Branch[T, S]]]</code> <p>The branch registry of the graph.</p> required <code>trigger</code> <code>NextNode[T, S]</code> <p>The node that spawned the branch.</p> required Source code in <code>src/edgygraph/graph/hooks.py</code> <pre><code>async def on_spawn_branch_end(self, state: T, shared: S, branch: Branch[T, S], trigger: NextNode[T, S], branch_registry: dict[SingleSource[T, S], list[Branch[T, S]]], join_registry: dict[Join[T, S], list[Branch[T, S]]]):\n    \"\"\"\n    Called after a branch is spawned.\n\n    Args:\n        state: The state of the graph.\n        shared: The shared state of the graph.\n        branch: The branch that was spawned.\n        branch_registry: The branch registry of the graph.\n        trigger: The node that spawned the branch.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/graph/hooks/#src.edgygraph.graph.hooks.GraphHook.on_merge_start","title":"<code>on_merge_start(state, result_states, changes)</code>  <code>async</code>","text":"<p>Called when the merge process starts.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>T</code> <p>The old state of the graph.</p> required <code>result_states</code> <code>list[T]</code> <p>The result states of the nodes.</p> required <code>changes</code> <code>list[dict[tuple[Hashable, ...], Change]]</code> <p>The changes that will be applied to the state.</p> required Source code in <code>src/edgygraph/graph/hooks.py</code> <pre><code>async def on_merge_start(self, state: T, result_states: list[T], changes: list[dict[tuple[Hashable, ...], Change]]) -&gt; None:\n    \"\"\"\n    Called when the merge process starts.\n\n    Args:\n        state: The old state of the graph.\n        result_states: The result states of the nodes.\n        changes: The changes that will be applied to the state.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/graph/hooks/#src.edgygraph.graph.hooks.GraphHook.on_merge_conflict","title":"<code>on_merge_conflict(state, changes, conflicts)</code>  <code>async</code>","text":"<p>Called when a merge conflict occurs.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>T</code> <p>The old state of the graph.</p> required <code>changes</code> <code>list[dict[tuple[Hashable, ...], Change]]</code> <p>The changes that will be applied to the state.</p> required <code>conflicts</code> <code>dict[tuple[Hashable, ...], list[Change]]</code> <p>The conflicts that occurred during the merge process.</p> required Source code in <code>src/edgygraph/graph/hooks.py</code> <pre><code>async def on_merge_conflict(self, state: T, changes: list[dict[tuple[Hashable, ...], Change]], conflicts: dict[tuple[Hashable, ...], list[Change]]) -&gt; None:\n    \"\"\"\n    Called when a merge conflict occurs.\n\n    Args:\n        state: The old state of the graph.\n        changes: The changes that will be applied to the state.\n        conflicts: The conflicts that occurred during the merge process.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/graph/hooks/#src.edgygraph.graph.hooks.GraphHook.on_merge_end","title":"<code>on_merge_end(state, result_states, changes, merged_state)</code>  <code>async</code>","text":"<p>Called when the merge process ends.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>T</code> <p>The old state of the graph.</p> required <code>result_states</code> <code>list[T]</code> <p>The result states of the nodes.</p> required <code>changes</code> <code>list[dict[tuple[Hashable, ...], Change]]</code> <p>The changes that have been applied to the state.</p> required <code>merged_state</code> <code>T</code> <p>The new merged state of the graph.</p> required Source code in <code>src/edgygraph/graph/hooks.py</code> <pre><code>async def on_merge_end(self, state: T, result_states: list[T], changes: list[dict[tuple[Hashable, ...], Change]], merged_state: T) -&gt; None:\n    \"\"\"\n    Called when the merge process ends.\n\n    Args:\n        state: The old state of the graph.\n        result_states: The result states of the nodes.\n        changes: The changes that have been applied to the state.\n        merged_state: The new merged state of the graph.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/graph/hooks/#src.edgygraph.graph.hooks.GraphHook.on_graph_end","title":"<code>on_graph_end(state, shared)</code>  <code>async</code>","text":"<p>Called when the graph execution ends.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>T</code> <p>The final state of the graph.</p> required <code>shared</code> <code>S</code> <p>The final shared data.</p> required Source code in <code>src/edgygraph/graph/hooks.py</code> <pre><code>async def on_graph_end(self, state: T, shared: S) -&gt; None:\n    \"\"\"\n    Called when the graph execution ends.\n\n    Args:\n        state: The final state of the graph.\n        shared: The final shared data.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/graph/hooks/#src.edgygraph.graph.hooks.GraphHook.on_error","title":"<code>on_error(error, state, shared)</code>  <code>async</code>","text":"<p>Called when an error occurs during the graph execution.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>Exception</code> <p>The error that occurred.</p> required <p>Returns:</p> Type Description <code>Exception | None</code> <p>The error to raise, or None not to raise an error.</p> Source code in <code>src/edgygraph/graph/hooks.py</code> <pre><code>async def on_error(self, error: Exception, state: T, shared: S) -&gt; Exception | None:\n    \"\"\"\n    Called when an error occurs during the graph execution.\n\n    Args:\n        error: The error that occurred.\n\n    Returns:\n       The error to raise, or None not to raise an error.\n    \"\"\"\n\n    return error\n</code></pre>"},{"location":"api/graph/types/","title":"Types","text":""},{"location":"api/graph/types/#src.edgygraph.graph.types.Types","title":"<code>Types</code>","text":"<p>Typeguards for runtime typechecking.</p> Source code in <code>src/edgygraph/graph/types.py</code> <pre><code>class Types[T: StateProtocol, S: SharedProtocol]:\n    \"\"\"\n    Typeguards for runtime typechecking.\n    \"\"\"\n\n    @classmethod\n    def is_node_tupel(cls, edge: tuple[Any, ...]) -&gt; TypeGuard[NodeTupel[T, S]]:\n        return len(edge) &gt;= 2 and (cls.is_single_source(edge[0]) and cls.is_only_node_tuple(edge[1:-1]) and cls.is_next(edge[-1]))\n\n    @classmethod\n    def is_only_node_tuple(cls, edge: tuple[Any, ...]) -&gt; TypeGuard[tuple[*tuple[T, S]]]:\n        return all(isinstance(n, Node) for n in edge)\n\n    @classmethod\n    def is_next(cls, x: Any) -&gt; TypeGuard[Next[T, S]]:\n        return (\n            cls.is_resolved_next(x) or\n            callable(x)\n        )\n\n    @classmethod\n    def is_resolved_next(cls, x: Any) -&gt; TypeGuard[ResolvedNext[T, S]]:\n        return (\n            cls.is_single_next(x) or\n            cls.is_single_next_sequence(x)\n        )\n\n    @classmethod\n    def is_single_next_sequence(cls, x: Any) -&gt; TypeGuard[Sequence[SingleNext[T, S]]]:\n        return isinstance(x, Sequence) and all(cls.is_single_next(n) for n in cast(Sequence[Any], x))\n\n\n    @classmethod\n    def is_single_next(cls, x: Any) -&gt; TypeGuard[SingleNext[T, S]]:\n        return (\n            x is None or\n            x is END or\n            isinstance(x, Node)\n        )\n\n    @classmethod\n    def is_source(cls, x: Any) -&gt; TypeGuard[Source[T, S]]:\n        return (\n            cls.is_single_source(x) or\n            (isinstance(x, Sequence) and all(cls.is_single_source(n) for n in cast(Sequence[Any], x)))\n        )\n\n    @classmethod\n    def is_single_source(cls, x: Any) -&gt; TypeGuard[SingleSource[T, S]]:\n        return (\n            x is START or   \n            isinstance(x, Node)\n        )\n\n    @classmethod\n    def is_single_source_sequence(cls, x: Any) -&gt; TypeGuard[Sequence[SingleSource[T, S]]]:\n        return isinstance(x, Sequence) and all(cls.is_single_source(n) for n in cast(Sequence[Any], x))\n\n    @classmethod\n    def is_error_source(cls, x: Any) -&gt; TypeGuard[ErrorSource[T, S]]:\n        return (\n            cls.is_single_error_source(x) or\n            (isinstance(x, Sequence) and all(cls.is_single_error_source(n) for n in cast(Sequence[Any], x)))\n        )\n\n    @classmethod\n    def is_single_error_source(cls, x: Any) -&gt; TypeGuard[SingleErrorSource[T, S]]:\n        return (\n            (isinstance(x, type) and issubclass(x, Exception)) or\n            (isinstance(x, tuple) and len(cast(tuple[Any], x)) == 2 and isinstance(x[0], Node) and isinstance(x[1], type) and issubclass(x[1], Exception))\n        )\n\n    @classmethod\n    def is_single_error_source_sequence(cls, x: Any) -&gt; TypeGuard[Sequence[SingleErrorSource[T, S]]]:\n        return isinstance(x, Sequence) and all(cls.is_single_error_source(n) for n in cast(Sequence[Any], x)) and len(cast(Sequence[Any], x)) &gt; 1   \n</code></pre>"},{"location":"api/graph/types/#src.edgygraph.graph.types.Config","title":"<code>Config</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for the edge.</p> <p>Attributes:</p> Name Type Description <code>instant</code> <code>bool</code> <p>If the edge should be executed parallel to the source node. Instant edges are traversed recursively. Make sure to avoid infinite loops.</p> Source code in <code>src/edgygraph/graph/types.py</code> <pre><code>class Config(BaseModel):\n    \"\"\"\n    Configuration for the edge.\n\n    Attributes:\n        instant: If the edge should be executed parallel to the source node. Instant edges are traversed recursively. Make sure to avoid infinite loops.\n    \"\"\"\n\n    instant: bool = False\n</code></pre>"},{"location":"api/graph/types/#src.edgygraph.graph.types.ErrorConfig","title":"<code>ErrorConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for the error edge.</p> <p>Attributes:</p> Name Type Description <code>propagate</code> <code>bool</code> <p>If the error should be propagated to the next error edge. If False, the error is caught and the graph continues.</p> Source code in <code>src/edgygraph/graph/types.py</code> <pre><code>class ErrorConfig(BaseModel):\n    \"\"\"\n    Configuration for the error edge.\n\n    Attributes:\n        propagate: If the error should be propagated to the next error edge. If False, the error is caught and the graph continues.\n    \"\"\"\n\n    propagate: bool = False\n</code></pre>"},{"location":"api/graph/types/#src.edgygraph.graph.types.BaseEntry","title":"<code>BaseEntry</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base class for the values of edge indexing dictionaries of a branch.</p> <p>Do not instantiate directly.</p> <p>Attributes:</p> Name Type Description <code>next</code> <code>Next[T, S]</code> <p>The unresolved targets of the edge.</p> <code>index</code> <code>int</code> <p>The original index of the entry in the list of edges of the branch.</p> Source code in <code>src/edgygraph/graph/types.py</code> <pre><code>class BaseEntry[T: StateProtocol, S: SharedProtocol](BaseModel):\n    \"\"\"\n    Base class for the values of edge indexing dictionaries of a branch.\n\n    Do not instantiate directly.\n\n    Attributes:\n        next: The unresolved targets of the edge.\n        index: The original index of the entry in the list of edges of the branch.\n    \"\"\"\n\n    next: Next[T, S]\n    index: int\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    def model_post_init(self, __context: Any):\n        if type(self) is BaseEntry:\n            raise Exception(\"BaseEntry is not meant to be instantiated directly.\") # Safeguard\n</code></pre>"},{"location":"api/graph/types/#src.edgygraph.graph.types.Entry","title":"<code>Entry</code>","text":"<p>               Bases: <code>BaseEntry[T, S]</code></p> <p>A value of the edge indexing dictionary of a branch.</p> <p>Attributes:</p> Name Type Description <code>next</code> <code>Next[T, S]</code> <p>The unresolved targets of the edge.</p> <code>index</code> <code>int</code> <p>The original index of the entry in the list of edges.</p> <code>config</code> <code>Config</code> <p>The configuration of the edge.</p> Source code in <code>src/edgygraph/graph/types.py</code> <pre><code>class Entry[T: StateProtocol, S: SharedProtocol](BaseEntry[T, S]):\n    \"\"\"\n    A value of the edge indexing dictionary of a branch.\n\n    Attributes:\n        next: The unresolved targets of the edge.\n        index: The original index of the entry in the list of edges.\n        config: The configuration of the edge.\n    \"\"\"\n\n    config: Config = Field(default_factory=Config)\n</code></pre>"},{"location":"api/graph/types/#src.edgygraph.graph.types.ErrorEntry","title":"<code>ErrorEntry</code>","text":"<p>               Bases: <code>BaseEntry[T, S]</code></p> <p>A value of the error edge indexing dictionary of a branch.</p> <p>Attributes:</p> Name Type Description <code>next</code> <code>Next[T, S]</code> <p>The unresolved targets of the edge.</p> <code>index</code> <code>int</code> <p>The original index of the entry in the list of edges.</p> <code>config</code> <code>ErrorConfig</code> <p>The configuration of the edge.</p> Source code in <code>src/edgygraph/graph/types.py</code> <pre><code>class ErrorEntry[T: StateProtocol, S: SharedProtocol](BaseEntry[T, S]):\n    \"\"\"\n    A value of the error edge indexing dictionary of a branch.\n\n    Attributes:\n        next: The unresolved targets of the edge.\n        index: The original index of the entry in the list of edges.\n        config: The configuration of the edge.\n    \"\"\"\n\n    config: ErrorConfig = Field(default_factory=ErrorConfig)\n</code></pre>"},{"location":"api/graph/types/#src.edgygraph.graph.types.NextNode","title":"<code>NextNode</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A node that is the target of an edge.</p> <p>Attributes:</p> Name Type Description <code>node</code> <code>Node[T, S]</code> <p>The node.</p> <code>reached_by</code> <code>Entries[T, S]</code> <p>The edge that targeted this node.</p> Source code in <code>src/edgygraph/graph/types.py</code> <pre><code>class NextNode[T: StateProtocol, S: SharedProtocol](BaseModel):\n    \"\"\"\n    A node that is the target of an edge.\n\n    Attributes:\n        node: The node.\n        reached_by: The edge that targeted this node.\n    \"\"\"\n\n    node: Node[T, S]\n    reached_by: Entries[T, S]\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"api/graph_hooks/interactive_debug/","title":"Interactive debug","text":""},{"location":"api/graph_hooks/interactive_debug/#src.edgygraph.graph_hooks.interactive_debug.InteractiveDebugHook","title":"<code>InteractiveDebugHook</code>","text":"<p>               Bases: <code>GraphHook[T, S]</code></p> <p>A hook that prints the state and shared data at each step of the graph execution and pauses for user input. Useful for interactive debugging.</p> Source code in <code>src/edgygraph/graph_hooks/interactive_debug.py</code> <pre><code>class InteractiveDebugHook[T: State, S: Shared](GraphHook[T, S]):\n    \"\"\"\n    A hook that prints the state and shared data at each step of the graph\n    execution and pauses for user input. Useful for interactive debugging.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self._renderer = GraphRenderer[T, S]()\n\n    def _pause(self) -&gt; None:\n        self._renderer.render_rule(style=\"dim\")\n        input(\"Press Enter to continue...\")\n\n    async def on_graph_start(self, state: T, shared: S) -&gt; None:\n        self._renderer.render_graph_start(state, shared)\n        self._pause()\n\n    async def on_step_start(self, state: T, shared: S, nodes: list[NextNode[T, S]]) -&gt; None:\n        self._renderer.render_step_start(nodes)\n        self._pause()\n\n    async def on_merge_conflict(\n        self,\n        state: T,\n        changes: list[dict[tuple[Hashable, ...], Change]],\n        conflicts: dict[tuple[Hashable, ...], list[Change]],\n    ) -&gt; None:\n        self._renderer.render_merge_conflict(conflicts)\n        self._pause()\n\n    async def on_merge_end(\n        self,\n        state: T,\n        result_states: list[T],\n        changes: list[dict[tuple[Hashable, ...], Change]],\n        merged_state: T,\n    ) -&gt; None:\n        self._renderer.render_merge_end(changes)\n        self._pause()\n\n    async def on_step_end(self, state: T, shared: S, nodes: list[NextNode[T, S]]) -&gt; None:\n        self._renderer.render_step_end(state, shared, nodes)\n        self._pause()\n\n    async def on_graph_end(self, state: T, shared: S) -&gt; None:\n        self._renderer.render_graph_end(state, shared)\n        self._pause()\n</code></pre>"},{"location":"api/graph_hooks/node_print/","title":"Node print","text":""},{"location":"api/graph_hooks/node_print/#src.edgygraph.graph_hooks.node_print.NodePrintHook","title":"<code>NodePrintHook</code>","text":"<p>               Bases: <code>GraphHook[T, S]</code></p> <p>A hook that prints the execiting nodes before and after execution in each branch.</p> <p>Parameters:</p> Name Type Description Default <code>renderer</code> <code>GraphRenderer[T, S] | None</code> <p>The GraphRenderer to use for printing the nodes. If not provided, the default renderer will be used.</p> <code>None</code> Source code in <code>src/edgygraph/graph_hooks/node_print.py</code> <pre><code>class NodePrintHook[T: StateProtocol = StateProtocol, S: SharedProtocol = SharedProtocol](GraphHook[T, S]):\n    \"\"\"\n    A hook that prints the execiting nodes before and after execution in each branch.\n\n    Args:\n        renderer: The GraphRenderer to use for printing the nodes. If not provided, the default renderer will be used.\n    \"\"\"\n\n    def __init__(self, renderer: GraphRenderer[T, S] | None = None) -&gt; None:\n        self.renderer = renderer or GraphRenderer()\n\n\n    async def on_graph_start(self, state: T, shared: S) -&gt; None:\n        self.renderer.render_graph_start(state, shared)\n\n    async def on_step_start(self, state: T, shared: S, nodes: list[NextNode[T, S]]) -&gt; None:\n        self.renderer.render_step_start(nodes)\n\n    async def on_step_end(self, state: T, shared: S, nodes: list[NextNode[T, S]]) -&gt; None:\n        self.renderer.render_step_end_footer(nodes)\n\n    async def on_graph_end(self, state: T, shared: S) -&gt; None:\n        self.renderer.render_graph_end(state, shared)\n\n    async def on_spawn_branch_end(self, state: T, shared: S, branch: Branch[T, S], trigger: NextNode[T, S], branch_registry: dict[SingleSource[T, S], list[Branch[T, S]]], join_registry: dict[Join[T, S], list[Branch[T, S]]]):\n        self.renderer.render_spawn_branch_end(branch, trigger)\n        self.renderer.render_branch_overview(branch_registry, join_registry)\n</code></pre>"}]}